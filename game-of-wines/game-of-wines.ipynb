{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Data Science to Understand What Makes Wine Taste Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Exploration\n",
    "\n",
    "In this section, we'll do some exploratory analysis to understand the nature of our data and the underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, import some necessary libraries. \n",
    "\n",
    "### Click the below cell block and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for displaying DataFrames\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import supplementary visualization code visuals.py from project root folder\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of these libraries:\n",
    "* [numpy](http://www.numpy.org/) is a package in python that is used for scientific computing. It supports higher-order mathematical functions, higher dimensional arrays, matrices and other data structures.\n",
    "* [pandas](https://pandas.pydata.org/) is a very popular library that is used for a lot of data analysis and statistics related problems.\n",
    "* [time](https://docs.python.org/3.7/library/time.html) - standard module in python that allows for time related functions\n",
    "* [display](http://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html?highlight=display) is a module in the IPython toolkit that helps you display data structures in a nice, readable format.\n",
    "* [matplotlib](https://matplotlib.org/) is a very popular visualization library that lets you create a wide array of figures, charts and graphs in the IPython Notebook\n",
    "* [seaborn](https://seaborn.pydata.org/index.html) is another visualization tool that uses matplotlib underneath, and provides you with easy-to-use APIs for visualization. It also makes your graphs more prettier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we'll load the dataset for red wines, and display the first 5 columns. Run the below cell block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Red Wines dataset\n",
    "data = pd.read_csv(\"data/winequality-red.csv\", sep=';')\n",
    "\n",
    "# Display the first five records\n",
    "display(data.head(n=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's do some basic preliminary analysis of our data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll begin by first seeing if our data has any missing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the features in the data-set and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last column *quality* is a metric of how good a specific wine was rated to be. For our purposes, let's consider all wines with ratings 7 and above to be of very good quality, wines with 5 and 6 to be of average quality, and wines less than 5 to be of insipid quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wines = data.shape[0]\n",
    "\n",
    "# Number of wines with quality rating above 6\n",
    "quality_above_6 = data.loc[(data['quality'] > 6)]\n",
    "n_above_6 = quality_above_6.shape[0]\n",
    "\n",
    "# Number of wines with quality rating below 5\n",
    "quality_below_5 = data.loc[(data['quality'] < 5)]\n",
    "n_below_5 = quality_below_5.shape[0]\n",
    "\n",
    "# Number of wines with quality rating between 5 to 6\n",
    "quality_between_5 = data.loc[(data['quality'] >= 5) & (data['quality'] <= 6)]\n",
    "n_between_5 = quality_between_5.shape[0]\n",
    "\n",
    "# Percentage of wines with quality rating above 6\n",
    "greater_percent = n_above_6*100/n_wines\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of wine data: {}\".format(n_wines))\n",
    "print(\"Wines with rating 7 and above: {}\".format(n_above_6))\n",
    "print(\"Wines with rating less than 5: {}\".format(n_below_5))\n",
    "print(\"Wines with rating 5 and 6: {}\".format(n_between_5))\n",
    "print(\"Percentage of wines with quality 7 and above: {:.2f}%\".format(greater_percent))\n",
    "\n",
    "# Some more additional data analysis\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell block to see the distributions on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize skewed continuous features of original data\n",
    "vs.distribution(data, \"quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most fines fall under **average quality (between 5 and 6)**. Wines which were rated high are in the lower hundreds, whereas there are very few wines that aren't tasty enough (low ratings).\n",
    "\n",
    "Next, since our aim is to predict the quality of wines, weâ€™ll now extract the last column and store it separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Exploring Relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data, alpha = 0.3, figsize = (40,40), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr()\n",
    "#display(correlation)\n",
    "plt.figure(figsize=(14, 12))\n",
    "heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe containing only pH and fixed acidity columns to visualize their co-relations\n",
    "fixedAcidity_pH = data[['pH', 'fixed acidity']]\n",
    "\n",
    "#Initialize a joint-grid with the dataframe, using seaborn library\n",
    "gridA = sns.JointGrid(x=\"fixed acidity\", y=\"pH\", data=fixedAcidity_pH, size=6)\n",
    "\n",
    "#Draws a regression plot in the grid \n",
    "gridA = gridA.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "\n",
    "#Draws a distribution plot in the same grid\n",
    "gridA = gridA.plot_marginals(sns.distplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedAcidity_citricAcid = data[['citric acid', 'fixed acidity']]\n",
    "g = sns.JointGrid(x=\"fixed acidity\", y=\"citric acid\", data=fixedAcidity_citricAcid, size=6)\n",
    "g = g.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "g = g.plot_marginals(sns.distplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedAcidity_density = data[['density', 'fixed acidity']]\n",
    "gridB = sns.JointGrid(x=\"fixed acidity\", y=\"density\", data=fixedAcidity_density, size=6)\n",
    "gridB = gridB.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "gridB = gridB.plot_marginals(sns.distplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatileAcidity_quality = data[['quality', 'volatile acidity']]\n",
    "g = sns.JointGrid(x=\"volatile acidity\", y=\"quality\", data=volatileAcidity_quality, size=6)\n",
    "g = g.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "g = g.plot_marginals(sns.distplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can visualize relationships of discreet values better with a bar plot\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1,figsize=(10,6))\n",
    "sns.barplot(x='quality', y='volatile acidity', data=volatileAcidity_quality, ax=axs)\n",
    "plt.title('quality VS volatile acidity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_alcohol = data[['alcohol', 'quality']]\n",
    "\n",
    "g = sns.JointGrid(x=\"alcohol\", y=\"quality\", data=quality_alcohol, size=6)\n",
    "g = g.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "#g = g.plot_marginals(sns.distplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=1,figsize=(10,6))\n",
    "sns.barplot(x='quality', y='alcohol', data=quality_alcohol, ax=axs)\n",
    "plt.title('quality VS alcohol')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select any two features of your choice and view their relationship\n",
    "featureA = 'pH'\n",
    "featureB = 'alcohol'\n",
    "featureA_featureB = data[[featureA, featureB]]\n",
    "\n",
    "g = sns.JointGrid(x=featureA, y=featureB, data=featureA_featureB, size=6)\n",
    "g = g.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n",
    "g = g.plot_marginals(sns.distplot)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1,figsize=(10,6))\n",
    "sns.barplot(x=featureA, y=featureB, data=featureA_featureB, ax=axs)\n",
    "plt.title('quality VS alcohol')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection:\n",
    "\n",
    "Detecting outliers in the data is extremely important in the data preprocessing step of any analysis. The presence of outliers can often skew results which take into consideration these data points. There are many \"rules of thumb\" for what constitutes an outlier in a dataset. Here, we will use [Tukey's Method for identfying outliers](http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/): An **outlier step** is calculated as **1.5** times the **interquartile range (IQR)**. A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal.\n",
    "\n",
    "In the code block below:\n",
    "\n",
    "* Assign the value of the 25th percentile for the given feature to Q1. Use np.percentile for this.\n",
    "* Assign the value of the 75th percentile for the given feature to Q3. Again, use np.percentile.\n",
    "* Assign the calculation of an outlier step for the given feature to step.\n",
    "* Optionally remove data points from the dataset by adding indices to the outliers list.\n",
    "\n",
    "**NOTE:** If you choose to remove any outliers, ensure that the sample data does not contain any of these points!\n",
    "Once you have performed this implementation, the dataset will be stored in the variable good_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each feature find the data points with extreme high or low values\n",
    "for feature in data.keys():\n",
    "    \n",
    "    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(data[feature], q=25)\n",
    "    \n",
    "    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(data[feature], q=75)\n",
    "    \n",
    "    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    interquartile_range = Q3 - Q1\n",
    "    step = 1.5 * interquartile_range\n",
    "    \n",
    "    # Display the outliers\n",
    "    print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    display(data[~((data[feature] >= Q1 - step) & (data[feature] <= Q3 + step))])\n",
    "    \n",
    "# OPTIONAL: Select the indices for data points you wish to remove\n",
    "outliers  = []\n",
    "\n",
    "# Remove the outliers, if any were specified\n",
    "good_data = data.drop(data.index[outliers]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Machine Learning to Predict the Quality of Wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: \n",
    "\n",
    "### First, we'll apply some transforms to convert our regression problem into a classification problem. Then, we'll use our data to create feature-set and target labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the splits for categories. 1-4 will be poor quality, 5-6 will be average, 7-10 will be great\n",
    "bins = [1,4,6,10]\n",
    "\n",
    "#0 for low quality, 1 for average, 2 for great quality\n",
    "quality_labels=[0,1,2]\n",
    "data['quality_categorical'] = pd.cut(data['quality'], bins=bins, labels=quality_labels, include_lowest=True)\n",
    "\n",
    "#Displays the first 2 columns\n",
    "display(data.head(n=2))\n",
    "\n",
    "# Split the data into features and target label\n",
    "quality_raw = data['quality_categorical']\n",
    "features_raw = data.drop(['quality', 'quality_categorical'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, shuffle and split our data-set into training and testing subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_raw, \n",
    "                                                    quality_raw, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [scikit-learn](http://scikit-learn.org/) is a handy data science and machine learning library that lets you use ML algorithms in easy to use APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Supervised Learning Models\n",
    "**The following are some of the supervised learning models that are currently available in** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **that you may choose from:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Creating a Training and Predicting Pipeline\n",
    "To properly evaluate the performance of each model you've chosen, it's important that you create a training and predicting pipeline that allows you to quickly and effectively train models using various sizes of training data and perform predictions on the testing data. Your implementation here will be used in the following section.\n",
    "In the code block below, you will need to implement the following:\n",
    " - Import `fbeta_score` and `accuracy_score` from [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Fit the learner to the sampled training data and record the training time.\n",
    " - Perform predictions on the test data `X_test`, and also on the first 300 training points `X_train[:300]`.\n",
    "   - Record the total prediction time.\n",
    " - Calculate the accuracy score for both the training subset and testing set.\n",
    " - Calculate the F-score for both the training subset and testing set.\n",
    "   - Make sure that you set the `beta` parameter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will write a function that will accept a ML algorithm of our choice, and use our data to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import two classification metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_predict_evaluate(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: quality training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: quality testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit/train the learner to the training data using slicing with 'sample_size' \n",
    "    using .fit(training_features[:], training_labels[:])\n",
    "    \"\"\"\n",
    "    start = time() # Get start time of training\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size]) #Train the model\n",
    "    end = time() # Get end time of training\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the predictions on the first 300 training samples(X_train), \n",
    "    and also predictions on the test set(X_test) using .predict()\n",
    "    \"\"\"\n",
    "    start = time() # Get start time\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    \n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F1-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5, average='micro')\n",
    "        \n",
    "    # Compute F1-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5, average='micro')\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Initial Model Evaluation\n",
    "In the code cell, you will need to implement the following:\n",
    "- Import the three supervised learning models you've discussed in the previous section.\n",
    "- Initialize the three models and store them in `'clf_A'`, `'clf_B'`, and `'clf_C'`.\n",
    "  - Use a `'random_state'` for each model you use, if provided.\n",
    "  - **Note:** Use the default settings for each model â€” you will tune one specific model in a later section.\n",
    "- Calculate the number of records equal to 1%, 10%, and 100% of the training data.\n",
    "  - Store those values in `'samples_1'`, `'samples_10'`, and `'samples_100'` respectively.\n",
    "\n",
    "**Note:** Depending on which algorithms you chose, the following implementation may take some time to run!\n",
    "\n",
    "Further reading: https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any three supervised learning classification models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = GaussianNB()\n",
    "clf_B = DecisionTreeClassifier(max_depth=None, random_state=None)\n",
    "clf_C = RandomForestClassifier(max_depth=None, random_state=None)\n",
    "\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100\n",
    "# HINT: samples_1 is 1% of samples_100\n",
    "\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)*10/100)\n",
    "samples_1 = int(len(y_train)*1/100)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict_evaluate(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "#print(results)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.visualize_classification_performance(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Why does Gaussian Naive Bayes perform poorly compared to the other methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf_B, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "## Feature Importance\n",
    "\n",
    "An important task when performing supervised learning on a dataset like the census data we study here is determining which features provide the most predictive power. By focusing on the relationship between only a few crucial features and the target label we simplify our understanding of the phenomenon, which is most always a useful thing to do. In the case of this project, that means we wish to identify a small number of features that most strongly predict the quality of wines.\n",
    "\n",
    "Choose a scikit-learn classifier (e.g., adaboost, random forests) that has a `feature_importance_` attribute, which is a function that ranks the importance of features according to the chosen classifier.  In the next python cell fit this classifier to training set and use this attribute to determine the top 5 most important features for the wines dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Extracting Feature Importance\n",
    "Choose a `scikit-learn` supervised learning algorithm that has a `feature_importance_` attribute availble for it. This attribute is a function that ranks the importance of each feature when making predictions based on the chosen algorithm.\n",
    "\n",
    "In the code cell below, you will need to implement the following:\n",
    " - Import a supervised learning model from sklearn if it is different from the three used earlier.\n",
    " - Train the supervised model on the entire training set.\n",
    " - Extract the feature importances using `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a supervised learning model that has 'feature_importances_'\n",
    "model = RandomForestClassifier(max_depth=None, random_state=None)\n",
    "\n",
    "# Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "print(X_train.columns)\n",
    "print(importances)\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = RandomForestClassifier(max_depth=None, random_state=None)\n",
    "\n",
    "# Create the parameters or base_estimators list you wish to tune, using a dictionary if needed.\n",
    "# Example: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "\n",
    "\"\"\"\n",
    "n_estimators: Number of trees in the forest\n",
    "max_features: The number of features to consider when looking for the best split\n",
    "max_depth: The maximum depth of the tree\n",
    "\"\"\"\n",
    "parameters = {'n_estimators': [10, 20, 30], 'max_features':[3,4,5, None], 'max_depth': [5,6,7, None]}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5, average=\"micro\")\n",
    "\n",
    "# TODO: Perform grid search on the claszsifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5, average=\"micro\")))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(best_clf)\n",
    "print(\"\\nFinal accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5,  average=\"micro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, you can test out your model by giving it a bunch of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Give inputs in this order: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide,\n",
    "total sulfur dioxide, density, pH, sulphates, alcohol\n",
    "\n",
    "\"\"\"\n",
    "wine_data = [[8, 0.2, 0.16, 1.8, 0.065, 3, 16, 0.9962, 3.42, 0.92, 9.5],\n",
    "            [8, 0, 0.16, 1.8, 0.065, 3, 16, 0.9962, 3.42, 0.92, 1 ],\n",
    "            [7.4, 2, 0.00, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 0.6]]\n",
    "               \n",
    "# Show predictions\n",
    "for i, quality in enumerate(best_clf.predict(wine_data)):\n",
    "    print(\"Predicted quality for Wine {} is: {}\".format(i+1, quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What conclusions can you draw based on the above observations? Would you say that the model is more good at predicting average quality wines? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS:\n",
    "1. Try solving this exercise again as a regression problem. Some of the common algorithms you can try from sklearn are *DecisionTreeRegressor*, *RandomForestRegressor*, and using *AdaBoostRegressor* with *DecisionTreeRegressor*. Some of the performance metrics that you might need to use in place of Accuracy and f1score are Mean Squared Error and R2Score\n",
    "\n",
    "2. Try using the White Wines data-set in place of the Red Wines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
